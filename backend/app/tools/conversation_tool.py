from llama_index.core.llms import ChatMessage
from llama_index.core.program import LLMTextCompletionProgram
from llama_index.core.output_parsers import PydanticOutputParser
from app.config.prompts import roleplay_prompt, conversation_feedback_prompt,\
                        roleplay_param_extraction_prompt
from app.schemas.agent_schema import RoleplayParams
from app.config.llm import gemini


from typing import List, Callable, Optional, Any

class ConversationTools:
    """
    A class to handle conversation tools for roleplay simulation and feedback in language learning.

    Attributes:
        llm (Optional[Any]): The language model used for generating responses.

    Methods:
        _run_tool(prompt: str, user_input: str) -> str:
            Executes a tool with the given prompt and user input, returning the model's response.

        get_tools() -> List[Callable]:
            Returns a list of available conversation tools.

        roleplay_tool(topic: str, context: str, ai_role: str, user_input: str) -> str:
            Simulates a roleplay conversation based on the provided topic, context, and AI role.

        conversation_feedback_tool(user_input: str) -> str:
            Provides feedback on a conversation based on the user's input.
    """
    def __init__(self, llm : Optional[Any] = None):
        self.llm = llm
        

    def _run_tool(self, prompt: str, user_input: str) -> str:
        messages = [
            ChatMessage(role="system", content=prompt),
            ChatMessage(role="user", content=user_input),
        ]
        return self.llm.chat(messages)
    

    def get_tools(self) -> List[Callable]:
        """
        Retrieves the list of conversation tools available for use.

        Returns:
            List[Callable]: A list of callable tools for conversation handling.
        """
        return [
            self.roleplay_tool,
            self.conversation_feedback_tool,
        ]
    
    def roleplay_tool(self, user_input: str = "") -> str:
        """
        Simulates a roleplay conversation using the specified topic, context, and AI role.

        Args:
            topic (str): The topic of the conversation.
            context (str): The context or setting of the conversation.
            ai_role (str): The role the AI should assume in the conversation.
            user_input (str): The user's input to the conversation.

        Returns:
            str: The response generated by the language model.
        """
        program = LLMTextCompletionProgram.from_defaults(
                output_parser=PydanticOutputParser(output_cls=RoleplayParams),
                prompt_template_str=roleplay_param_extraction_prompt,
                verbose=True,
                llm=gemini,
            )
        response = program(text=user_input)
        prompt = roleplay_prompt.format(topic=response.topic, context=response.context,
                                        ai_role=response.ai_role)
        return self._run_tool(prompt, user_input)

    def conversation_feedback_tool(self, user_input: str) -> str:
        """
        Provides feedback on a conversation based on the user's input.

        Args:
            user_input (str): The user's input for which feedback is to be provided.

        Returns:
            str: The feedback generated by the language model.
        """
        return self._run_tool(conversation_feedback_prompt, user_input)
